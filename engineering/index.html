<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vikram Anantha - Engineering</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="icon" type="image/png" href="../images/markivx.png">
</head>
<body>
    <div class="container">
        <div id="header-placeholder"></div>
        <main>
            <div class="title-card">
                <h1>Engineering Portfolio</h1>
            </div>
            <div class="engineering-container">
                
                <!-- Education Section -->
                <div class="education-section content-box">
                    <h2>Education</h2>
                    <div id="education-content" class="education-content">
                        <!-- Education items will be dynamically inserted here -->
                    </div>
                </div>

                <!-- Expertise Section -->
                <div class="expertise-section content-box">
                    <h2>Expertise</h2>
                    <div class="expertise-content">
                        <p>Technical Skills:</p>
                        <ul>
                            <li>Python, C++, Java, JavaScript, HTML, CSS, SQL</li>
                            <li>Gaussian Splat</li>
                            <li>PyTorch, TensorFlow, OpenCV, ROS</li>
                            <li>Git, Docker, Amazon Web Services</li>
                        </ul>
                        <p>Areas of Interest:</p>
                        <ul>
                            <li>Autonomous Vehicles</li>
                            <li>Applied Computer Vision</li>
                            <li>Smart Cities</li>
                            <li>Robotics</li>
                        </ul>
                    </div>
                </div>

                <!-- Experience Section (Full Width) -->
                <div class="experience-section content-box">
                    <h2>Experience</h2>
                    <div id="experience-content" class="experience-content">
                        <!-- Experience items will be dynamically inserted here -->
                    </div>
                </div>
            </div>
        </main>

        <div id="footer-placeholder"></div>
    </div>

    <script src="../header.js"></script>
    <script src="../footer.js"></script>
    <script>
        // Load header and footer when the page loads
        window.onload = function() {
            loadHeader();
            loadFooter();
            
            // Education data array
            const education = [
                {
                    logo: "https://upload.wikimedia.org/wikipedia/commons/3/36/Michigan_Wolverines_Block_M.png",
                    alt: "University of Michigan Logo",
                    name: "University of Michigan",
                    degree: "Computer Science",
                    duration: "August 2024 - Present",
                    gpa: "3.96",
                    coursework: [
                        "Data Structures & Algorithms",
                        "Computer Organization",
                        "Robot Human Interaction",
                        "Circuits",
                        "Discrete Mathematics"
                    ]
                },
                {
                    logo: "https://assets.scorebooklive.com/uploads/production/school/19216/image/Lexington__MA__Minutemen_Logo.png",
                    alt: "LHS Logo",
                    name: "Lexington High School",
                    duration: "August 2020 - May 2024",
                    gpa: "4.0",
                    coursework: [
                        "AP Computer Science A",
                        "AP Computer Science Principles",
                        "AP Physics C",
                        "AP Calculus BC",
                        "AP Statistics"
                    ]
                }
            ];

            // Function to create education items
            function createEducationItem(edu) {
                const item = document.createElement('div');
                item.className = 'education-item';
                
                const logo = document.createElement('img');
                logo.src = edu.logo;
                logo.alt = edu.alt;
                logo.className = 'eee-icon';
                
                const text = document.createElement('div');
                text.className = 'education-text';
                
                const header = document.createElement('div');
                header.className = 'education-header';
                
                const name = document.createElement('h3');
                const nameLink = document.createElement('a');
                nameLink.href = edu.link;
                nameLink.textContent = edu.name;
                nameLink.target = "_blank";
                nameLink.rel = "noopener noreferrer";
                name.appendChild(nameLink);
                
                const degree = document.createElement('p');
                degree.textContent = edu.degree;
                
                const duration = document.createElement('p');
                duration.textContent = edu.duration;
                
                const expandButton = document.createElement('button');
                expandButton.className = 'expand-button';
                expandButton.innerHTML = '<i class="fas fa-chevron-down"></i>';
                
                // Create right container for the button
                const rightContainer = document.createElement('div');
                rightContainer.className = 'right-container';
                rightContainer.appendChild(expandButton);
                
                header.appendChild(name);
                header.appendChild(degree);
                header.appendChild(duration);
                header.appendChild(rightContainer); // Append container instead of button
                
                const details = document.createElement('div');
                details.className = 'education-details';
                
                const gpa = document.createElement('p');
                gpa.textContent = `GPA: ${edu.gpa}`;
                
                const coursework = document.createElement('div');
                coursework.className = 'coursework';
                
                const courseworkTitle = document.createElement('p');
                courseworkTitle.textContent = "Relevant Coursework:";
                
                const courseworkList = document.createElement('ul');
                edu.coursework.forEach(course => {
                    const li = document.createElement('li');
                    li.textContent = course;
                    courseworkList.appendChild(li);
                });
                
                coursework.appendChild(courseworkTitle);
                coursework.appendChild(courseworkList);
                
                details.appendChild(gpa);
                details.appendChild(coursework);
                
                text.appendChild(header);
                text.appendChild(details);
                
                item.appendChild(logo);
                item.appendChild(text);
                
                // Add click event to toggle details - TARGET THE HEADER
                header.addEventListener('click', (event) => {
                    // Prevent click on links within the container from triggering collapse
                    if (event.target.closest('a') || event.target.closest('.expand-button')) {
                        // If the click is on the button itself, toggle anyway
                        if (!event.target.closest('.expand-button')) return;
                    }
                    const isExpanded = details.classList.toggle('expanded');
                    expandButton.innerHTML = isExpanded ? 
                        '<i class="fas fa-chevron-up"></i>' : 
                        '<i class="fas fa-chevron-down"></i>';
                });
                
                return item;
            }

            // Insert education items into the page
            const educationContainer = document.getElementById('education-content');
            education.forEach(edu => {
                educationContainer.appendChild(createEducationItem(edu));
            });

            // Experience data array
            const experiences = [
                {
                    logo: "https://pbs.twimg.com/profile_images/1350691793394946048/sc3Hpcsr_200x200.png",
                    alt: "Stellantis Logo",
                    name: "Stellantis",
                    link: "https://www.stellantis.com/en",
                    role: "Software Engineering Intern",
                    duration: "May 2025 - Present",
                    description: "<p>Advanced Driver-Assistance Systems (ADAS) Engineer</p>"
                },
                {
                    logo: "https://images.crunchbase.com/image/upload/c_pad,h_256,w_256,f_auto,q_auto:eco,dpr_1/irk4bkrls8rlqrqwd7ci",
                    alt: "Capoom Logo",
                    name: "Capoom",
                    link: "https://www.capoom.com/",
                    role: "Software Engineering Intern, via Perot Jain Tech Lab at Mcity Program",
                    duration: "Jan 2025 - Present",
                    description: `
                    <p>
                        <b>Developing method for automatic 3D Gaussian Splat model creation of UofM's Mcity</b> as an inexpensive, lightweight testbed for autonomous vehicle companies to train and test their vehicles
                    </p>
                    <p>
                        Established the data collection pipeline using Lucid Cameras with Arena SDK and implemented 3D modeling using Gaussian Splatting techniques through <a href='https://www.capturingreality.com/'>Reality Capture</a> and <a href='https://www.jawset.com/'>Post Shot</a> software to create detailed small-scale models. 
                        I explored two hierarchical Gaussian splatting methods - <a href='https://github.com/Linketic/CityGaussian'>CityGaussianV2</a> and <a href='https://github.com/graphdeco-inria/hierarchical-3d-gaussians'>Hierarchical 3D Gaussians</a> - to effectively scale up these models while maintaining detail quality and minimizing computational resources. 
                    </p>
                    `,
                    images: [
                        "images/engineering/realitycapture.png",
                    ]
                },
                {
                    logo: "https://upload.wikimedia.org/wikipedia/commons/3/36/Michigan_Wolverines_Block_M.png",
                    alt: "University of Michigan Logo",
                    name: "Robotic & Optimization for Analysis of Human Motion Lab",
                    link: "https://www.roahmlab.com/",
                    role: "Research Assistant",
                    duration: "Aug 2024 - Present",
                    paper: "https://drive.google.com/file/d/1aC-cdw4XmY19WyBp9W5B8dSc1mJTcwET/view?usp=sharing",
                    description: `
                    <p>
                        <b>Worked on a novel pipeline for safe mobile manipulation by implementing scene representation through 3D Gaussian Splatting, which efficiently generates detailed, manipulable 3D models from RGB-D images. </b>
                    </p>
                    <p>
                        I integrated object detection capabilities combining <a href="https://github.com/IDEA-Research/GroundingDINO">GroundingDINO</a> for zero-shot target identification and <a href="https://github.com/facebookresearch/segment-anything">Meta's Segment Anything Model</a> for precise object segmentation, allowing the system to identify specific clusters of Gaussians associated with target objects. 
                        I established grasp detection functionality using <a href="https://github.com/graspnet/anygrasp_sdk">AnyGrasp</a> to generate optimal gripper positions for the Fetch robot to safely manipulate objects in novel environments. 
                        I leveraged <a href="https://github.com/UZ-SLAMLab/ORB_SLAM3">ORBSLAM3</a> to process continuous camera feeds, track features across frames, and generate accurate camera positions that were essential for creating the initial point cloud used to produce Normalized Gaussians for scene representation.
                        Together, my contributions formed the foundation for a computationally efficient and safe autonomous system capable of understanding scenes, identifying objects, and calculating appropriate grasping positions without prior environment knowledge.
                    </p>
                    `,
                    images: [
                        "images/engineering/grounding_dino.jpg",
                        "images/engineering/3dgs_example.jpg",
                    ]
                },
                {
                    logo: "https://i.vimeocdn.com/player/375755?sig=a8d6fa180b32ddccd8e86ae4dbaf8477b07f7b37fe5cad0758dd93a4ace2551d&v=1",
                    alt: "Constant Therapy Health Logo",
                    name: "Constant Therapy Health",
                    link: "https://constanttherapyhealth.com/constant-therapy/",
                    role: "Software Engineer Intern",
                    duration: "June 2021 - Aug 2024",
                    description: `
                        <p>
                            Constant Therapy, a digital health therapeutic technology company that develops tablet-based software to help stroke patients relearn everyday skills through digital-therapy tasks.
                            <b>Worked on the Task progression Visualizer, which is a ReactJS web page that analyzes how patients progress through tasks, and from that, tasks can be reworked to optimally help patients. </b>
                            My project was to make the Visualizer work on the company's newest version of data, which required me to make significant changes to the backend JavaScript and Python code.
                        </p>
                        <p>
                            <b>Improved their speech recognition / grammar detection with LLMs system for stroke patients. </b>
                            I fine-tuned Meta's Wav2Vec Automatic Speech Recognition model to recognize phonemes rather than full words, which had a false negative rate 4x lower than Google's speech recognition model. 
                            I also worked on a Large Language Model to detect the accuracy of grammar in a patient's response. 
                            My work is now currently in the Constant Therapy app, being used by patients globally.
                        </p>
                        `
                },
                {
                    logo: "https://upload.wikimedia.org/wikipedia/commons/0/0c/MIT_logo.svg",
                    alt: "MIT Logo",
                    name: "Auto ID Lab, MIT",
                    link: "https://autoid.mit.edu/",
                    role: "Research Intern",
                    duration: "June 2023 - Sept 2023",
                    github: "https://github.com/vikramanantha/mit-2fa-summer2023",
                    description: `
                    <p>The aim of this project was to <b>create a secure visual confirmation system for autonomous vehicles (AVs) communicating with road-side units (RSUs), like a traffic light. </b>
                        For an RSU to verify the identity of an AV, the AV flashes its headlights in a specific sequence. 
                        My project was to detect the recognition of this sequence using Python. 
                        I worked solely, as a paid intern under the supervision of Post-doc Dajiang Suo and Professor Sanjay Sarma of MIT.
                    </p>
                    <ul>
                        <li>This system first detects a vehicle using a YOLOv8 Computer Vision model, and cropping the frame to just the vehicle. </li>
                        <li>It then detects whether the vehicle's headlights were on or off per frame, by turning each RGB cropped image into a binary image, showing where the bright regions are. </li>
                        <li>I evaluated several approaches that have been previously studied (including a few that use machine learning), but developed a new approach that uses binary images, so as to maximize the detection accuracy and minimize processing latency. </li>
                        <li>The system finally determines whether the sequence of headlight flashes follows the sequence originally sent to the AV, accounting for possible errors.</li>
                    </ul>
                    <p>Biggest challenge: process identity while the vehicle is moving through a street intersection in less than 1 second & to work in a lot of situations: variable lighting, different types of vehicles, different shapes of headlights, etc.</p>
                    `,
                    images: [
                        "images/engineering/mit_flowchart.png",
                        "images/engineering/mit_lights_onoff.jpg"
                    ]
                },
                {
                    logo: "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSUSx6WeeB157MZjjAScsdccpuhFjy1kzByFQ&s",
                    alt: "Columbia Logo",
                    name: "Center for Smart Street Scapes, Columbia University",
                    link: "https://cs3-erc.org/",
                    role: "Research Intern",
                    duration: "June 2023 - Sept 2023",
                    github: "https://github.com/vikramanantha/columbia-pedapp-summer2023",
                    paper: "https://doi.org/10.1109/IV55156.2024.10588544",
                    description: `
                        <p>The aim of this project was to <b>create a phone application and a backend server that warns pedestrians at street intersections about potential collisions with vehicles. </b>
                            I solely created this, with the guidance of PhD student Yongjie Fu and Professor Sharon Di, both of Columbia University.</p>
                        <p>I used Python and React Native to develop this system. 
                            The app uses React Native as a framework for the front-end user interface, and communicates via MQTT messages to a Python backend server.</p>
                        <p>The app ran the following steps:</p>
                        <ul>
                            <li>Location coordinates are sent to, and processed by the backend server.</li>
                            <li>Backend server constructs a trajectory that predicts where the pedestrian is likely to be in the next 5 seconds.</li>
                            <li>Backend Server receives data about where vehicles currently are, and where their predicted trajectories will be over the next 5 seconds.</li>
                            <li>Based on this data, the server predicts if there is likely to be a collision between pedestrians and each vehicle.</li>
                            <li>As appropriate, the server sends back warnings to the pedestrian's phones.</li>
                        </ul>
                        <p>The app was optimized for multiple devices of any make and model to connect to it, and maximized accuracy and minimized latency in harsh situations (i.e., weak connection).</p>
                        <p>
                            Paper published at the IEEE IV 2024 Intelligent Vehicles Symposium <a href="https://doi.org/10.1109/IV55156.2024.10588544">here</a>.
                        </p>
                        `,
                    images: [
                        "images/engineering/field_test_image.jpeg",
                        "images/engineering/ped_app_flowchart_v5.png",
                    ]
                },
                {
                    logo: "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT4oHdQYnnDK85X9ZKw28iNtIlX6SBXkUczow&s",
                    alt: "HELM Learning Logo",
                    name: "HELM Learning",
                    link: "https://web.archive.org/web/20240414172814/https://helmlearning.com/",
                    role: "Co-founder, Teacher, Developer",
                    duration: "Apr 2020 - May 2024",
                    github: "https://github.com/vikramanantha/helmlearning",
                    paper: "https://arxiv.org/abs/2209.03489",
                    description: `<ul>
                        <p>
                            I created <b>HELM Learning, a platform for middle and high school students to teach classes to K-12 students worldwide for free. </b>
                            This platform connected 4,000+ students to 90+ student-teachers. 
                            I built the back-end system using a Python Flask app, which I hosted on an AWS EC2 instance that connected to a MySQL Database. 
                        </p>
                        <p>
                            To accommodate for HELM's growing number of classes, I created a <b>Machine Learning Recommendation Algorithm to suggest students new classes they should sign up for based on their previously shown interests in certain subjects. </b>
                            This was implemented into the current sign up page after a student signs up for a class.
                        </p>
                        <p>
                            This algorithm used an MLP classifier to create a model for each class, which would output the probability of a student taking that class. Once all models have given an output, the top 3 probabilities are taken, and those classes are recommended to the student. A random 4th class was added as a control to know if the algorithm worked or not
                        </p>
                        <p>
                            Presented at the Massachusetts State Science and Engineering Fair, receiving 4th place.
                        </p>
                    </ul>`,
                    images: [
                        "images/engineering/helm_recalg_flowchart.png",
                        "images/engineering/helm_recalg_impl.png",
                    ]
                }
            ];

            // Function to create experience items
            function createExperienceItem(exp) {
                const item = document.createElement('div');
                item.className = 'experience-item';
                
                const logo = document.createElement('img');
                logo.src = exp.logo;
                logo.alt = exp.alt;
                logo.className = 'eee-icon';
                
                const text = document.createElement('div');
                text.className = 'experience-text';
                
                const header = document.createElement('div');
                header.className = 'experience-header';
                
                const name = document.createElement('h3');
                const nameLink = document.createElement('a');
                nameLink.href = exp.link;
                nameLink.textContent = exp.name;
                nameLink.target = "_blank";
                nameLink.rel = "noopener noreferrer";
                name.appendChild(nameLink);
                
                const role = document.createElement('p');
                role.textContent = exp.role;
                
                const duration = document.createElement('p');
                duration.textContent = exp.duration;
                
                const expandButton = document.createElement('button');
                expandButton.className = 'expand-button';
                expandButton.innerHTML = '<i class="fas fa-chevron-down"></i>';
                
                // Create a container for the icons and expand button
                const rightContainer = document.createElement('div');
                rightContainer.className = 'right-container';
                
                // Add paper link if available
                if (exp.paper) {
                    const paperLink = document.createElement('a');
                    paperLink.href = exp.paper;
                    paperLink.target = '_blank';
                    paperLink.className = 'social-link';
                    paperLink.innerHTML = '<i class="fas fa-file-alt"></i>';
                    rightContainer.appendChild(paperLink);
                }
                
                // Add GitHub link if available
                if (exp.github) {
                    const githubLink = document.createElement('a');
                    githubLink.href = exp.github;
                    githubLink.target = '_blank';
                    githubLink.className = 'social-link';
                    githubLink.innerHTML = '<i class="fab fa-github"></i>';
                    rightContainer.appendChild(githubLink);
                }
                
                rightContainer.appendChild(expandButton);
                header.appendChild(rightContainer);
                
                header.appendChild(name);
                header.appendChild(role);
                header.appendChild(duration);
                
                const description = document.createElement('div');
                description.className = 'experience-description';
                description.innerHTML = exp.description;
                
                // Add images if they exist
                if (exp.images && exp.images.length > 0) {
                    const imagesContainer = document.createElement('div');
                    imagesContainer.className = 'experience-images';
                    exp.images.forEach(imgPath => {
                        // Create a container for each image
                        const imageContainer = document.createElement('div');
                        imageContainer.className = 'experience-image-container';
                        
                        const img = document.createElement('img');
                        img.src = `../${imgPath}`;
                        img.alt = `${exp.name} image`; 
                        img.className = 'experience-image';
                        
                        // Append image to its container
                        imageContainer.appendChild(img);
                        // Append the container to the main images container
                        imagesContainer.appendChild(imageContainer);
                    });
                    description.appendChild(imagesContainer);
                }
                
                text.appendChild(header);
                text.appendChild(description);
                
                item.appendChild(logo);
                item.appendChild(text);
                
                // Add click event to toggle description - TARGET THE HEADER
                header.addEventListener('click', (event) => {
                    // Prevent click on links within the container from triggering collapse
                    if (event.target.closest('a') || event.target.closest('.expand-button')) {
                        // If the click is on the button itself OR links within right-container, toggle anyway
                         if (!event.target.closest('.right-container a') && !event.target.closest('.expand-button')) return;
                    }
                    const isExpanded = description.classList.toggle('expanded');
                    expandButton.innerHTML = isExpanded ? 
                        '<i class="fas fa-chevron-up"></i>' : 
                        '<i class="fas fa-chevron-down"></i>';
                });
                
                return item;
            }

            // Insert experience items into the page
            const experienceContainer = document.getElementById('experience-content');
            experiences.forEach(exp => {
                experienceContainer.appendChild(createExperienceItem(exp));
            });
        };
    </script>
</body>
</html>
